---
title: "RNASeqQuant: an R package for RNA-Seq quantification"
author: 
- Yulong Niu
- Ruben Garrido-Oter
package: RNASeqQuant
date: "`r Sys.Date()`"
bibliography: RSQref.bib
csl: nature.csl
header-includes:
  - \usepackage{amsmath}
  - \usepackage{mathtools}
  - \newcommand{\Pro}{\mathrm{P}}
  - \newcommand{\tildel}[1]{\widetilde{l_{#1}}}
output:
  BiocStyle::pdf_document:
    toc: true
    latex_engine: pdflatex
    includes:
      in_header: header.tex
  BiocStyle::html_document:
    toc: true
    toc_float: true
    includes:
      before_body: header.html
vignette: >
  %\usepackage[utf8]{inputenc}
  %\VignetteIndexEntry{RNASeqQuant: an R package for RNA-Seq quantification}
  %\VignetteEngine{knitr::rmarkdown}
---

```{r style, echo=FALSE, results='asis', message=FALSE}
options(tinytex.verbose = TRUE)
BiocStyle::markdown()
knitr::opts_chunk$set(tidy = FALSE,
                      warning = FALSE,
                      message = FALSE)
```

``` {r macro, echo=FALSE, results='hide', message=FALSE}
RNASeqQuant <- function() {"*[RNASeqQuant](https://github.com/YulongNiu/RNASeqQuant)*"}
Robject <- function(x){sub('%obj%', x, '<span style="background-color:#F0F0F0;color:#404040;font-family:\'Lucida Console\', monospace">%obj%</span>')}
Rclass <- function(x){sub('%obj%', x, '<span style="font-family:\'Times New Roman\', Times, serif;font-style: italic">%obj%</span>')}
```

# Overview

`r RNASeqQuant()` implements both expectation maximization and gradient descent for RNA-Seq quantification.

# Models

## EM model for single species

In single species, if $T=\{t_1, t_2, \dots, t_K\}$ is the set of transcripts (with length $l_i$ for $t_i$) and the copy number of $t_i$ is $c_i$, we define $\rho_k=\frac{c_k}{\sum\limits_{t \in T}c_t} = \frac{c_k}{M}$ is the relative abundances of $t_i$, where $M$ is the total copy number, so that $\sum\limits_{k=1}^K \rho_k=1$.

For a single species RNA-Seq data-set, let $F=\{f_1, f_2, \dots, f_N\}$ be the set of transcription fragments (reads) in a total number of $N=|F|$. Fragments mapped to the transcript $t_i$ composes the set $F_t \in F$ in a number of $X_t=|F_t|$. We assume that all fragments in $F$ have the same length $m$. In $t_i$, the number of position in which the fragment can start is $\tildel{t} = l_t - m + 1$. $\tildel{t}$ is also called *effective length* [@bray2016near; @pachter2011models].

After mapping, we can observe the alignment positions of $f_i$, which can be mapped to several transcripts, but we do not know the exact transcript. The estimated parameters is $\alpha=\{\alpha_1, \alpha_2, \dots, \alpha_K\}$, $\sum\limits_{k=1}^K \alpha_k=1$. The probability that the fragment $f$ comes from the transcripts $t$ is:

\begin{equation}
\begin{split}
\Pro(f \in t) &= \frac{\rho_t M \tildel{t}}{\sum\limits_{k=1}^{K} \rho_k M \tildel{k}} \\
&= \frac{\rho_t \tildel{t}}{\sum\limits_{k=1}^{K} \rho_k \tildel{k}} \\
&= \alpha_t
\end{split}
(\#eq:1)
\end{equation}

If $f$ comes from $t$, the probability that $f$ mapped to a certain position of $t$ is:

\begin{equation}
\begin{split}
\Pro(\mathrm{pos}|f \in t) = \frac{1}{\tildel{t}}
\end{split}
(\#eq:2)
\end{equation}

Combining \@ref(eq:1) and \@ref(eq:2), the probability that $f$ mapped to a certain position of $t$ is:

\begin{equation}
\begin{split}
\Pro(\mathrm{pos}, f \in t) = \frac{\alpha_t}{\tildel{t}}
\end{split}
(\#eq:3)
\end{equation}

The logarithm of likelihood (LL) function is:

\begin{equation}
\begin{split}
LL &= \sum\limits_{f \in F} \log \left(\Pro(\mathrm{pos}|\alpha)\ \right) \\
&= \sum\limits_{f \in F} \log \left( \sum_{k=1}^{K} \Pro(\mathrm{pos}, f \in t_k|\alpha) \right) \\
&= \sum\limits_{f \in F} \log \left( \sum_{k = 1}^{K} y_k \frac{\alpha_k}{\tildel{k}} \right) \\
\end{split}
(\#eq:4)
\end{equation}

where $y_k$ is the $\{0, 1\}$ indicator.

We use expectationâ€“maximization (EM) algorithm to estimate $\alpha$. In the $n$ iteration, $\Pro(f \in t_1|\mathrm{pos}, \alpha^{(n)})$ equals to:

\begin{equation}
\begin{split}
\Pro(f \in t_1|\mathrm{pos}, \alpha^{(n)}) &= \frac{\Pro(f \in t_1, \mathrm{pos}|\alpha^{(n)})}{\sum\limits_{k=1}^{K} \Pro(f \in t_k, \mathrm{pos}|\alpha^{(n)})} \\
&= \frac{\alpha_1^{(n)} \frac{y_1}{\tildel{1}}}{\sum\limits_{k=1}^{K} \alpha_k^{(n)} \frac{y_k}{\tildel{k}}} \\
&= \lambda_1
\end{split}
(\#eq:5)
\end{equation}

where $\sum\limits_{k=1}^{K} \lambda_k = 1$.

\begin{equation}
\begin{split}
\alpha^{(n+1)} &= \argmax_\alpha \left( 
\sum_{f \in F} \sum_{k=1}^{K} \Pro(f \in t_k|\mathrm{pos}, \alpha^{(n)})  \log \left( \Pro(f \in t_1, \mathrm{pos}|\alpha^{(n)}) \right) 
\right) \\
&= \argmax_\alpha \left( 
\sum_{f \in F} \sum_{k=1}^{K} \lambda_k \log\left(
\alpha_k \frac{y_k}{\tildel{k}}
\right)
\right) \\
&= \argmax_\alpha \left(
\sum_{f \in F} \sum_{k=1}^{K}  \lambda_k \log\left(
\alpha_k
\right)
\right)
\end{split}
(\#eq:6)
\end{equation}

The $n+1$ estimation of $\alpha$ is:

\begin{equation*}
\begin{split}
\alpha_k^{(n+1)} &= \frac{\sum\limits_{f \in F} \lambda_k}{\sum\limits_{i=1}^{K} \sum\limits_{f \in F} \lambda_i} \\
&= \frac{\sum\limits_{f \in F} \lambda_k}{N}
,\ k=1, 2, \dots, K
\end{split}
\end{equation*}

## EM model for multiple species

For a mix species RNA-Seq data-set, species $A$ and $B$ for example, $R=\{r_1, r_2, \dots, r_U\}$ is the set of transcripts (with length $l_u$ for $r_u$) in species $A$ and $S=\{s_1, s_2, \dots, s_V\}$ is the set of transcripts (with length $l_v$ for $s_v$) in species $B$. Total transcripts in species $A$ and $B$ composes the set $T=\{t_1, t_2, \dots, t_{U+V}\}$. 

The relative abundances in $A$ and $B$ are $\rho_u$, $\sum\limits_{u=1}^U \rho_u= 1$ and $\theta_v$, $\sum\limits_{v=1}^V \theta_v= 1$, respectively. Similarly, we define:

\begin{equation}
\begin{split}
\Pro(f \in r_u) = \frac{\rho_u \tildel{u}}{\sum\limits_{r \in R} \rho_r \tildel{r}} = \alpha_u \\
\Pro(\mathrm{pos}, f \in r_u) = \frac{\alpha_u}{\tildel{u}}
\end{split}
(\#eq:7)
\end{equation}

\begin{equation}
\begin{split}
\Pro(f \in s_v) = \frac{\theta_v \tildel{v}}{\sum\limits_{s \in S} \theta_s \tildel{s}} = \beta_v \\
\Pro(\mathrm{pos}, f \in s_v) = \frac{\beta_v}{\tildel{v}}
\end{split}
(\#eq:8)
\end{equation}

The probability of single mapped fragment is:

\begin{equation}
\begin{split}
\Pro(\mathrm{pos}|\eta)  &= \Pro(\mathrm{pos}, f \in A|\eta) + \Pro(\mathrm{pos}, f \in B|\eta)\\
&= \Pro(\mathrm{pos} | f \in A, \eta) \Pro(f \in A) + \Pro(\mathrm{pos} | f \in B, \eta) \Pro(f \in B) \\
&= \sum_{i=1}^{U}m_i \frac{\alpha_i}{\tildel{i}} \Pro(f \in A) + \sum_{j=U+1}^{U+V}m_j \frac{\beta_j}{\tildel{j}} \Pro(f \in B) 
\end{split}
(\#eq:9)
\end{equation}

Thus, the parameters will be estimated are:

\begin{equation*}
\begin{split}
\eta=\{\alpha_1, \dots, \alpha_u, \beta_1, \dots, \beta_v,  \Pro(f \in A),  \Pro(f \in B)\}
\end{split}
\end{equation*}

In $n+1$ iteration, the parameters in the expanded EM algorithm:

\begin{equation}
\begin{split}
\lambda_i^{(n+1)} &= \frac{\alpha_i^{(n)} \frac{m_i}{\tildel{i}} \Pro(f \in A)}{\sum\limits_{i=1}^{U}\alpha_i^{(n)} \frac{m_i}{\tildel{i}} \Pro(f \in A) + \sum\limits_{j=U+1}^{U+V}\beta_j^{(n)} \frac{m_j}{\tildel{j}} \Pro(f \in B)}\\
\lambda_j^{(n+1)} &= \frac{\beta_j^{(n)} \frac{m_j}{\tildel{j}} \Pro(f \in A)}{\sum\limits_{i=1}^{U}\alpha_i^{(n)} \frac{m_i}{\tildel{i}} \Pro(f \in A) + \sum\limits_{j=U+1}^{U+V}\beta_j^{(n)} \frac{m_j}{\tildel{j}} \Pro(f \in B)}\\
\alpha_i^{(n+1)} &= \frac{\sum\limits_{f \in F} \lambda_i^{(n+1)}}{\sum\limits_{f \in F} \sum\limits_{i=1}^{U} \lambda_i^{(n+1)}} \\
\beta_j^{(n+1)} &= \frac{\sum\limits_{f \in F} \lambda_j^{(n+1)}}{\sum\limits_{f \in F} \sum\limits_{j=U+1}^{U+V} \lambda_j^{(n+1)}} \\
\Pro(f \in A)^{(n+1)} &= \frac{\sum\limits_{f \in F} \sum\limits_{i=1}^{U} \lambda_i^{(n+1)}}{\sum\limits_{f \in F} \sum\limits_{i=1}^{U} \lambda_i^{(n+1)} + \sum\limits_{f \in F} \sum\limits_{j=U+1}^{U+V} \lambda_j^{(n+1)}} = \frac{\sum\limits_{f \in F} \sum\limits_{i=1}^{U} \lambda_i^{(n+1)}}{N}\\
\Pro(f \in B)^{(n+1)} &= \frac{\sum\limits_{f \in F} \sum\limits_{j=U+1}^{U+V} \lambda_j^{(n+1)}}{\sum\limits_{f \in F} \sum\limits_{i=1}^{U} \lambda_i^{(n+1)} + \sum\limits_{f \in F} \sum\limits_{j=U+1}^{U+V} \lambda_j^{(n+1)}} = \frac{\sum\limits_{f \in F} \sum\limits_{j=U+1}^{U+V} \lambda_j^{(n+1)}}{N} 
\end{split}
(\#eq:10)
\end{equation}

## GD model for single species

The estimated parameters $\alpha=\{\alpha_1, \alpha_2, \dots, \alpha_K\}$ has restrictions: $\sum\limits_{k=1}^K \alpha_k=1$ and $\alpha_k \in [0, 1]$. We remove the restrictions by transforming $\alpha$ as:

\begin{equation*}
\begin{split}
\alpha_t &= \frac{f(x_t)}{\sum\limits_{k=1}^{K} f(x_k)} \\
&= \frac{f(x_t)}{Z}
\end{split}
\end{equation*}

where $x \in (-\infty, +\infty)$, $f(x) > 0$, and $f(x)$ is derivable. Possible candidates of $f(x)$ are:

| Name     | Equation                                          | Derivative                                | Range                    |
|----------|---------------------------------------------------|-------------------------------------------|--------------------------|
| Softmax  | $f(x)=e^x$                                        | $f'(x)=f(x)$                              | $(0,+\infty)$            |
| SoftPlus | $f(x)=\log(1+e^x)$                                | $f'(x)=\frac{1}{1+e^x}$                   | $(0,+\infty)$            |
| Softsign | $f(x)=\frac{1}{1+\abs{x}} + 1$                    | $f'(x)=\frac{1}{(1+\abs{x})^2}$           | $(0,2)$                  |
| Sigmoid  | $f(x)=\frac{1}{1+e^x}$                            | $f'(x)=f(x)(1-f(x))$                      | $(0,1)$                  |
| ISRU     | $f(x)=\frac{x}{\sqrt{1+ax^2}}+\frac{1}{\sqrt{a}}$ | $f'(x)=\left(\frac{1}{(1+ax)^2}\right)^3$ | $(0,\frac{2}{\sqrt{a}})$ |
| ArcTan   | $f(x)=\tan^{-1}(x)+\frac{\pi}{2}$                 | $f'(x)=\frac{1}{1+x^2}$                   | $(0,\pi)$                |
| TanH     | $f(x)=\frac{e^x-e^{-x}}{e^x+e^{-x}}+1$            | $f'(x)=1-f(x)^2$                          | $(0,1)$                  |


[^1]: Inverse square root unit

Thus the loss function is defined as negative logarithm of likelihood (NLL):

\begin{equation}
\begin{split}
NLL &= -\sum\limits_{f \in F} \log \left( \sum_{k = 1}^{K} y_k \frac{\alpha_k}{\tildel{k}} \right) \\
&=  -\sum\limits_{f \in F} \log \left( \sum_{k = 1}^{K} \frac{f(x_k)}{Z} \frac{y_k}{\tildel{k}} \right) \\
&=  -\sum\limits_{f \in F} \log \left( \sum_{k = 1}^{K} f(x_k) \frac{y_k}{\tildel{k}} - \log Z \right)
\end{split}
(\#eq:11)
\end{equation}


# References
